import os
import json
import re
import sqlite3
import datetime
from pathlib import Path
from urllib.parse import urlparse

from backend.core.config import settings  # ç”¨ä¾†æ‹¿ DATABASE_URL

# === åŸºæœ¬è¨­å®š ===

DATABASE_URL = settings.DATABASE_URL          # ä¾‹ï¼šsqlite:///./cards.db
MAPPING_PATH = Path("company_industry_mapping_v3.json")
ONLY_UPDATE_EMPTY = False                     # True = åªæ›´æ–° industry_category ç‚º NULL/ç©ºå­—ä¸²çš„
DRY_RUN = False                               # True = åªå°çµæœä¸å¯«å…¥ DB


# === å°å·¥å…· ===

def get_sqlite_path(db_url: str) -> str:
    """
    å¾ settings.DATABASE_URL å–å¾— SQLite æª”æ¡ˆè·¯å¾‘
    ä¾‹å¦‚: sqlite:///./cards.db  -> ./cards.db
    """
    if not db_url.startswith("sqlite:///"):
        raise ValueError(f"ç›®å‰è…³æœ¬åªæ”¯æ´ SQLiteï¼Œæ”¶åˆ°çš„ DATABASE_URL = {db_url}")

    # å»æ‰å‰ç¶´ sqlite:///
    path = db_url[len("sqlite:///"):]
    return path


def normalize_company_name(name: str) -> str:
    """
    å’Œä½ å‰é¢ pipeline ä¸€æ¨£çš„æ­£è¦åŒ–é‚è¼¯ï¼š
    - å»é ­å°¾ç©ºç™½
    - å…¨éƒ¨å°å¯«
    - ç§»é™¤ç©ºç™½/å…¨å½¢ç©ºç™½/tab
    - å»æ‰å¸¸è¦‹å…¬å¸å°¾ç¶´ï¼ˆco., ltd, inc...ï¼‰
    """
    if not name:
        return ""
    name = name.strip().lower()
    # ç§»é™¤ç©ºç™½/å…¨å½¢ç©ºç™½/tab
    name = re.sub(r"[ \u3000\t]+", "", name)
    # å»æ‰å¸¸è¦‹å…¬å¸å°¾ç¶´
    name = re.sub(r"(co\.?,?ltd\.?|corporation|corp\.?|inc\.?)$", "", name)
    return name.strip()


def load_mapping(path: Path) -> dict:
    """
    è¼‰å…¥ company_industry_mapping_v3.json
    é æœŸæ ¼å¼ï¼š{ normalized_name: { primary_label, labels, confidence, ... }, ... }
    """
    if not path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° mapping æª”æ¡ˆï¼š{path}")

    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, dict):
        raise ValueError(f"mapping æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œé æœŸç‚º dictï¼Œå¯¦éš›ç‚º: {type(data)}")

    print(f"âœ… è¼‰å…¥å…¬å¸ç”¢æ¥­ mappingï¼Œå…± {len(data)} ç­†å…¬å¸")
    return data


def build_candidate_keys(row) -> list[str]:
    """
    çµ¦ä¸€ç­† cards è³‡æ–™ï¼Œç”¢ç”Ÿã€Œå¯èƒ½å°å¾—ä¸Š mapping çš„ key å€™é¸åˆ—è¡¨ã€

    ç­–ç•¥ï¼š
    - åŒæ™‚è€ƒæ…® company_name_zh / company_name_en
    - æ¯å€‹åç¨±éƒ½ç¶“é normalize_company_name
    - å»æ‰ç©ºå­—ä¸² & é‡è¤‡
    """
    names = []

    zh = (row["company_name_zh"] or "").strip()
    en = (row["company_name_en"] or "").strip()

    if zh:
        names.append(zh)
    if en:
        names.append(en)

    candidates = []

    for name in names:
        # åŸå§‹ normalize
        key1 = normalize_company_name(name)
        if key1:
            candidates.append(key1)

        # é¡å¤–ï¼šç§»é™¤å¸¸è¦‹å…¬å¸å°¾ç¶´å† normalize ä¸€æ¬¡ï¼ˆé¿å…æˆ‘å€‘ä¹‹å‰å°‘å¯«ï¼‰
        # ä¾‹å¦‚ã€Œè‚¡ä»½æœ‰é™å…¬å¸ã€ã€Œæœ‰é™å…¬å¸ã€ã€Œå…¬å¸ã€ç­‰ç­‰
        tmp = re.sub(r"(è‚¡ä»½æœ‰é™å…¬å¸|æœ‰é™å…¬å¸|è‚¡ä»½æœ‰ é™å…¬å¸|å…¬å¸)$", "", name)
        tmp = tmp.strip()
        if tmp and tmp != name:
            key2 = normalize_company_name(tmp)
            if key2:
                candidates.append(key2)

    # å»é‡
    seen = set()
    unique = []
    for k in candidates:
        if k not in seen:
            seen.add(k)
            unique.append(k)
    return unique


def normalize_confidence(raw_conf) -> float:
    """
    æŠŠ mapping è£¡çš„ confidence æ­£è¦åŒ–æˆ 0.0 ~ 1.0 ä¹‹é–“çš„æµ®é»æ•¸
    - å¦‚æœæ˜¯ None / ç©º â†’ çµ¦ 0.9 ç•¶é è¨­
    - å¦‚æœ >1ï¼Œè¦–ç‚ºç™¾åˆ†æ¯”ï¼Œ/100
    """
    if raw_conf is None:
        return 0.9
    try:
        c = float(raw_conf)
    except (TypeError, ValueError):
        return 0.9

    if c > 1.0:
        c = c / 100.0
    # å¤¾åœ¨ 0~1 ä¹‹é–“
    c = max(0.0, min(1.0, c))
    return c


# === ä¸»æµç¨‹ ===

def main():
    print("ä½¿ç”¨ DATABASE_URL =", DATABASE_URL)

    # 1. è¼‰å…¥ mapping
    mapping = load_mapping(MAPPING_PATH)

    # 2. è§£æ SQLite è·¯å¾‘ä¸¦é€£ç·š
    db_path = get_sqlite_path(DATABASE_URL)
    print(f"ğŸ”— é€£ç·šåˆ° SQLite æª”æ¡ˆï¼š{db_path}")

    if not os.path.exists(db_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™åº«æª”æ¡ˆï¼š{db_path}")

    conn = sqlite3.connect(db_path)
    # row_factory è®“æˆ‘å€‘å¯ä»¥ç”¨ row["æ¬„ä½å"] æ–¹å¼å–å€¼
    conn.row_factory = sqlite3.Row

    try:
        cur = conn.cursor()

        # 3. æ’ˆå‡º cards è¡¨éœ€è¦çš„æ¬„ä½
        cur.execute("""
            SELECT
                id,
                company_name_zh,
                company_name_en,
                industry_category,
                classification_confidence,
                classification_reason,
                classified_at
            FROM cards
        """)
        rows = cur.fetchall()
        total = len(rows)
        print(f"ğŸ” å¾ cards è¡¨è®€åˆ° {total} ç­†åç‰‡")

        updated_rows = []
        updated_count = 0
        skipped_has_value = 0
        no_company_name = 0
        no_mapping_match = 0
        example_updates = []

        # 4. é€ç­†è™•ç†
        for row in rows:
            card_id = row["id"]
            
            # æº–å‚™æ‰€æœ‰å€™é¸ key
            candidate_keys = build_candidate_keys(row)

            if not candidate_keys:
                no_company_name += 1
                continue

            if ONLY_UPDATE_EMPTY:
                existing = row["industry_category"]
                if existing is not None and str(existing).strip() != "":
                    skipped_has_value += 1
                    continue

            info = None
            used_key = None

            # ä¾åºå˜—è©¦æ¯å€‹å€™é¸ key
            for key in candidate_keys:
                hit = mapping.get(key)
                if hit:
                    info = hit
                    used_key = key
                    break

            if not info:
                no_mapping_match += 1
                continue

            # === å¾ mapping å–æ¬„ä½ ===
            # 12 å¤§é¡ â†’ å¯«å…¥ cards.industry_category
            major = info.get("major_category_12")
            # ç´°æ¨™ç±¤ï¼šprimary_label + labels â†’ å¯«å…¥ cards.classification_reason
            primary = info.get("primary_label")
            labels = info.get("labels") or []
            raw_conf = info.get("confidence")

            # è‹¥ mapping è£¡æ²’ majorï¼Œå°±é€€å› primaryï¼Œå†ä¸è¡Œå°±çµ¦ã€Œä¸æ˜ï¼å…¶ä»–ã€
            new_industry = (major or primary or "ä¸æ˜/å…¶ä»–")

            # ç½®ä¿¡åº¦ç…§åŸæœ¬é‚è¼¯æ­£è¦åŒ–ï¼ˆ0~1ï¼‰
            new_conf = normalize_confidence(raw_conf)

            # çµ„ classification_reason
            reason_parts = []
            if primary:
                reason_parts.append(f"primary: {primary}")
            if labels:
                reason_parts.append("labels: " + ", ".join(labels))

            base_reason = " | ".join(reason_parts) if reason_parts else None
            if base_reason:
                new_reason = f"from_mapping_v3: {base_reason}, key={used_key}"
            else:
                new_reason = f"from_mapping_v3: key={used_key}"

            now = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")

            updated_rows.append(
                (
                    new_industry,
                    new_conf,
                    new_reason,
                    now,
                    card_id,
                )
            )
            updated_count += 1

            if len(example_updates) < 5:
                example_updates.append({
                    "id": card_id,
                    "company_name_zh": row["company_name_zh"],
                    "company_name_en": row["company_name_en"],
                    "used_key": used_key,
                    "industry_category": new_industry,
                    "classification_confidence": new_conf,
                    "classification_reason": new_reason,
                })

        # 5. å¯«å…¥æˆ– DRY_RUN
        print()
        print("ğŸ“Š å›å¡«çµæœçµ±è¨ˆï¼š")
        print(f"  ç¸½åç‰‡æ•¸ï¼š{total}")
        print(f"  âœ… é è¨ˆæ›´æ–°çš„åç‰‡æ•¸ï¼š{updated_count}")
        print(f"  âšª å·²æœ‰ç”¢æ¥­åˆ†é¡è€Œæœªæ›´æ–°ï¼ˆONLY_UPDATE_EMPTY=True æ‰æœƒç´¯åŠ ï¼‰ï¼š{skipped_has_value}")
        print(f"  ğŸš« æ²’æœ‰å…¬å¸åç¨±çš„åç‰‡ï¼š{no_company_name}")
        print(f"  â“ æ‰¾ä¸åˆ°å°æ‡‰ mapping çš„åç‰‡æ•¸ï¼š{no_mapping_match}")
        print()

        if example_updates:
            print("ğŸ‘‰ ç¯„ä¾‹æ›´æ–°å…§å®¹ï¼ˆå‰ 5 ç­†ï¼‰ï¼š")
            for ex in example_updates:
                print(
                    f"  - card_id={ex['id']}, "
                    f"company_zh={ex['company_name_zh']}, "
                    f"company_en={ex['company_name_en']}, "
                    f"industry={ex['industry_category']}, "
                    f"conf={ex['classification_confidence']:.3f}"
                )
        else:
            print("ï¼ˆæ²’æœ‰ä»»ä½•ç¬¦åˆæ¢ä»¶çš„æ›´æ–°ï¼‰")

        if DRY_RUN:
            print("ğŸ” ç›®å‰ç‚º DRY_RUN æ¨¡å¼ï¼Œä¸æœƒå¯¦éš›å¯«å…¥è³‡æ–™åº«ã€‚")
        else:
            # çœŸæ­£å¯«å…¥
            print("ğŸ’¾ æ­£åœ¨å¯«å…¥è³‡æ–™åº«...")
            cur.executemany(
                """
                UPDATE cards
                SET
                    industry_category = ?,
                    classification_confidence = ?,
                    classification_reason = ?,
                    classified_at = ?
                WHERE id = ?
                """,
                updated_rows,
            )
            conn.commit()
            print("âœ… å¯«å…¥å®Œæˆï¼")

    finally:
        conn.close()


if __name__ == "__main__":
    main()
