"""
AI ç”¢æ¥­åˆ†é¡æœå‹™ï¼ˆæ–°ç‰ˆï¼‰

åŠŸèƒ½ï¼š
- ä½¿ç”¨ OpenAI + web_search åšå…¬å¸ç”¢æ¥­åˆ†é¡
- å„ªå…ˆå¾ company_industry_mapping_v3.json è®€å–çµæœï¼Œæ‰¾ä¸åˆ°æ‰å‘¼å« GPT
- ä½¿ç”¨ 12 å¤§ç”¢æ¥­å¤§é¡
- å°å¤–ç¶­æŒåŸæœ¬ä»‹é¢ï¼š
    - classify_single(company_name, position) -> {category, confidence, reason}
    - classify_batch(cards) -> [{card_id, industry_category, confidence, reason, success}]
    - classify_single_with_retry(card, max_retries=3)
    - classify_batch_async(cards, task_id)
"""

import os
import re
import time
import json
import logging
import unicodedata
import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

from dotenv import load_dotenv
from openai import OpenAI
from .task_manager import task_manager

logger = logging.getLogger(__name__)

# å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼šservices â†’ backend â†’ å°ˆæ¡ˆæ ¹
BASE_DIR = Path(__file__).resolve().parents[2]

# æ˜ç¢ºå¾å°ˆæ¡ˆæ ¹ç›®éŒ„è¼‰å…¥ .env
load_dotenv(BASE_DIR / ".env")


class IndustryClassificationService:
    """
    AI äº§ä¸šåˆ†ç±»æœåŠ¡ï¼ˆæ–°ç‰ˆï¼‰

    ä¸»è¦æ”¹å‹•ï¼š
    - æ”¹ç‚ºä½¿ç”¨ 12 å¤§ç”¢æ¥­å¤§é¡ï¼ˆå°æ‡‰ major_category_12ï¼‰
    - å„ªå…ˆå¾ company_industry_mapping_v3.json è®€å–åˆ†é¡çµæœ
    - æ‰¾ä¸åˆ° mapping æ™‚æ‰å‘¼å« GPT + web_searchï¼Œä¸¦å°‡çµæœå¯«å› mapping
    - å°å¤–ä»‹é¢ç¶­æŒåŸæœ¬ï¼š
        - classify_single(company_name, position)
        - classify_batch(cards)
        - classify_single_with_retry(card, max_retries=3)
        - classify_batch_async(cards, task_id)
      å›å‚³çš„æ¬„ä½ä»ç‚ºï¼š
        - industry_category: å­—ä¸²ï¼ˆé€™æ¬¡æœƒæ˜¯ 12 å¤§é¡ï¼‰
        - confidence: int, 0â€“100
        - reason: å­—ä¸²ï¼ˆé€™æ¬¡æ”¾ description + labelsï¼‰
        - success: bool
    """

    # mapping æª”æ¡ˆè·¯å¾‘ï¼Œå„ªå…ˆç”¨ç’°å¢ƒè®Šæ•¸ï¼Œå¦å‰‡é è¨­æ”¾åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹
    MAPPING_PATH = Path(
        os.getenv(
            "INDUSTRY_MAPPING_PATH",
            BASE_DIR / "company_industry_mapping_v3.json",
        )
    )

    # 12 å¤§é¡æ¸…å–®ï¼ˆä¸»è¦æ˜¯æ–¹ä¾¿ log / æª¢æŸ¥ç”¨ï¼‰
    MAJOR_12 = {
        "è³‡è¨Šç§‘æŠ€",
        "é‡‘èä¿éšª",
        "è£½é€ æ¥­ï¼å·¥æ¥­æ‡‰ç”¨",
        "å»ºç¯‰ä¸å‹•ç”¢",
        "äº¤é€šé‹è¼¸ï¼ç‰©æµ",
        "é†«ç™‚å¥åº·ï¼ç”ŸæŠ€",
        "é¤é£²ï¼é›¶å”®ï¼é€šè·¯",
        "å»£å‘Šï¼åª’é«”ï¼è¡ŒéŠ·",
        "æ•™è‚²ï¼å­¸ç ”",
        "æ”¿åºœï¼å…¬éƒ¨é–€ï¼éç‡Ÿåˆ©",
        "å°ˆæ¥­æœå‹™ï¼ˆé¡§å•ï¼æ³•å‹™ï¼æœƒè¨ˆç­‰ï¼‰",
        "ä¸æ˜ï¼å…¶ä»–",
    }

    # çµ¦ GPT çš„ system promptï¼ˆå°±æ˜¯ä½ ä¹‹å‰é‚£ä»½ï¼Œç•¥å¾®æ•´ç†æ’ç‰ˆï¼‰
    SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½å°ˆé–€è² è²¬ã€Œå…¬å¸ç”¢æ¥­åˆ†é¡ã€çš„å°ˆæ¥­æ¨™è¨»å“¡ã€‚

ã€ä»»å‹™èªªæ˜ã€‘
æ ¹æ“šè¼¸å…¥çš„å…¬å¸åç¨±ï¼ˆå¯èƒ½åŒ…å«ä¸­æ–‡åç¨±èˆ‡è‹±æ–‡åç¨±ï¼‰ï¼Œå…ˆåˆ©ç”¨ç¶²è·¯æœå°‹æŸ¥è©¢è©²å…¬å¸ï¼Œå†ä¾ç…§å…¶ä¸»è¦æ¥­å‹™èˆ‡ç”¢å“ï¼Œè¼¸å‡ºç”¢æ¥­åˆ†é¡æ¨™ç±¤ã€‚

è¼¸å…¥æœƒé•·é€™æ¨£ï¼ˆå…¶ä¸­ä¸€å€‹å¯èƒ½ç‚ºç©ºå­—ä¸²ï¼‰ï¼š
- å…¬å¸ä¸­æ–‡åç¨±: {{company_name_zh}}
- å…¬å¸è‹±æ–‡åç¨±: {{company_name_en}}

ã€æœå°‹èˆ‡åˆ¤æ–·æµç¨‹ã€‘ï¼ˆè«‹å‹™å¿…é€æ­¥åŸ·è¡Œï¼‰
1. ä½¿ç”¨ç›®å‰å¯ç”¨çš„ã€Œç¶²è·¯æœå°‹ / Bing æœå°‹å·¥å…·ã€ï¼Œä»¥ä»¥ä¸‹é—œéµå­—çµ„åˆæŸ¥è©¢ï¼š
   - å…¬å¸ä¸­æ–‡åç¨±ï¼ˆè‹¥æœ‰ï¼‰ï¼‹ã€Œå®˜ç¶²ã€ã€Œå®˜æ–¹ç¶²ç«™ã€ã€Œå…¬å¸ç°¡ä»‹ã€
   - å…¬å¸è‹±æ–‡åç¨±ï¼ˆè‹¥æœ‰ï¼‰ï¼‹ã€Œofficial siteã€ã€Œaboutã€ã€Œcompanyã€
   - å…¬å¸åç¨± + ç”¢å“ã€æœå‹™ç›¸é—œå­—ï¼ˆå¦‚ã€Œsolutionã€ã€Œplatformã€ã€Œé›²ç«¯ã€ã€Œç³»çµ±ã€ç­‰ï¼‰
2. å„ªå…ˆåƒè€ƒçš„è³‡è¨Šä¾†æºï¼š
   - å…¬å¸å®˜æ–¹ç¶²ç«™ï¼ˆHomepage / About / Products / Servicesï¼‰
   - LinkedIn å…¬å¸é 
   - å„åœ‹å®˜æ–¹å•†æ¥­ç™»è¨˜ / å·¥å•†è³‡è¨Šç¶²ç«™
   - æœ‰å¯ä¿¡åº¦çš„æ–°èæˆ–å ±å°
3. é‡å°å…¬å¸å¯¦éš›æƒ…æ³ï¼Œæ•´ç†å‡ºï¼š
   - æ ¸å¿ƒç”¢å“æˆ–æœå‹™æ˜¯ä»€éº¼ï¼Ÿ
   - ä¸»è¦å®¢æˆ¶æ—ç¾¤æ˜¯èª°ï¼ˆB2B / B2C / æ”¿åºœç­‰ï¼‰ï¼Ÿ
   - å…¬å¸ä¸»è¦åœ¨è§£æ±ºä»€éº¼å•é¡Œï¼Œæˆ–ä½æ–¼å“ªå€‹ç”¢æ¥­éˆä½ç½®ï¼Ÿ
4. ä¾ã€Œä¸»è¦ç‡Ÿæ”¶ä¾†æºã€åˆ¤æ–·è©²å…¬å¸çš„ä¸»è¦ç”¢æ¥­ï¼Œä¸è¦è¢«å°‘æ•¸å‰¯æ¥­èª¤å°ã€‚
5. è‹¥å®Œå…¨æŸ¥ä¸åˆ°è³‡æ–™æˆ–è³‡è¨Šæ¥µå°‘ï¼Œæ‰å…è¨±çµ¦å‡ºéå¸¸ä½çš„ä¿¡å¿ƒåˆ†æ•¸ï¼Œä¸¦å°‡ primary_label è¨­ç‚ºè¼ƒå¯¬æ³›çš„é¡åˆ¥ï¼ˆä¾‹å¦‚ã€Œå…¶ä»–ã€ï¼‰ï¼Œä½†ä¸è¦æ†‘ç©ºæé€ ç´°ç¯€ã€‚

ã€12å¤§é¡åˆ—è¡¨ã€‘
1. è³‡è¨Šç§‘æŠ€
2. é‡‘èä¿éšª
3. è£½é€ æ¥­ï¼å·¥æ¥­æ‡‰ç”¨
4. å»ºç¯‰ä¸å‹•ç”¢
5. äº¤é€šé‹è¼¸ï¼ç‰©æµ
6. é†«ç™‚å¥åº·ï¼ç”ŸæŠ€
7. é¤é£²ï¼é›¶å”®ï¼é€šè·¯
8. å»£å‘Šï¼åª’é«”ï¼è¡ŒéŠ·
9. æ•™è‚²ï¼å­¸ç ”
10. æ”¿åºœï¼å…¬éƒ¨é–€ï¼éç‡Ÿåˆ©
11. å°ˆæ¥­æœå‹™ï¼ˆé¡§å•ï¼æ³•å‹™ï¼æœƒè¨ˆç­‰ï¼‰
12. ä¸æ˜ï¼å…¶ä»–

ã€æ¬„ä½å®šç¾©ã€‘
è«‹ä¾ç…§ä»¥ä¸‹è¦å‰‡è¼¸å‡ºä¸€å€‹ JSON ç‰©ä»¶ï¼ˆä¸èƒ½æœ‰é¡å¤–æ–‡å­—ï¼‰ï¼š

- major_category_12ï¼š
  - å¿…é ˆå¾ä¸Šé¢ 12 å¤§é¡ä¸­æŒ‘ä¸€å€‹æœ€è²¼è¿‘çš„åˆ†é¡åç¨±ã€‚
  - é™¤éå®Œå…¨æŸ¥ä¸åˆ°ä»»ä½•è³‡è¨Šï¼Œä¸è¦é¸ 12. å…¶ä»–ã€‚
  - è‹¥åŒæ™‚æ¶‰åŠå¤šé ˜åŸŸï¼Œè«‹ä¾ã€Œæ ¸å¿ƒç‡Ÿæ”¶ä¾†æºã€æ±ºå®šé¡åˆ¥ã€‚
  
- primary_labelï¼š
  - ä¸€å¥è©±çš„ã€Œä¸»è¦ç”¢æ¥­å¤§é¡ã€ï¼Œä¸­æ–‡çŸ­èªã€‚
  - ä¾‹ï¼šè³‡è¨Šç§‘æŠ€ã€é‡‘èä¿éšªã€è£½é€ æ¥­ã€å»£å‘Šè¡ŒéŠ·ã€æ•™è‚²è¨“ç·´ã€é†«ç™‚å¥åº·ã€é›¶å”®é›»å•†ã€æ”¿åºœæ©Ÿé—œã€éç‡Ÿåˆ©çµ„ç¹”ã€æ—…å®¿è§€å…‰ã€ç‰©æµé‹è¼¸ ç­‰ã€‚
  - è«‹æ ¹æ“šå¯¦éš›æŸ¥åˆ°çš„è³‡è¨Šè‡ªè¡Œé¸æ“‡æœ€è²¼åˆ‡çš„ç”¢æ¥­åç¨±ï¼Œå¯ä»¥ä¸æ˜¯ä¸Šè¿°èˆ‰ä¾‹è£¡çš„å­—çœ¼ï¼Œä½†å¿…é ˆè‡ªç„¶ä¸”å¸¸è¦‹ã€‚

- labelsï¼š
  - ä¸€å€‹å­—ä¸²é™£åˆ—ï¼ˆList of stringï¼‰ï¼ŒåŒ…å« 1ï½5 å€‹ç›¸é—œç´°æ¨™ç±¤ã€‚
  - ç”¨ä¾†è£œå……ç´°åˆ†é ˜åŸŸã€æŠ€è¡“æˆ–æœå‹™ï¼Œå…¨éƒ¨è¦ç”¨ä¸­æ–‡ã€‚
  - å¯ä»¥å¾ã€Œè¼ƒå¤§é¡åˆ¥ â†’ è¼ƒç´°é …ã€çš„æ–¹å¼æ›¸å¯«ï¼Œä¾‹å¦‚ï¼š
    - ["è³‡è¨Šç§‘æŠ€", "è»Ÿé«”é–‹ç™¼", "SaaS", "é›²ç«¯æœå‹™"]
    - ["é‡‘èä¿éšª", "ä¿éšªç§‘æŠ€", "ç·šä¸ŠæŠ•ä¿å¹³å°"]
  - è‹¥æœ‰ç‰¹å®š verticalï¼ˆå¦‚ã€Œé†«é™¢è³‡è¨Šç³»çµ±ã€ã€Œæ—…å®¿è¨‚æˆ¿å¹³å°ã€ã€Œå·¥æ¥­è¨­å‚™è£½é€ ã€ï¼‰ä¹Ÿå¯ä»¥å¯«é€²å»ã€‚

- descriptionï¼š
  - ä½¿ç”¨ 1ï½3 å¥ä¸­æ–‡ï¼Œèªªæ˜ç‚ºä»€éº¼é€™æ¨£åˆ†é¡ã€‚
  - è«‹ç›¡é‡å¼•ç”¨ä½ åœ¨ç¶²è·¯ä¸ŠæŸ¥åˆ°çš„é—œéµè³‡è¨Šï¼ˆä¾‹å¦‚ç”¢å“ã€æœå‹™ã€å®¢æˆ¶æ—ç¾¤ï¼‰ï¼Œåšæˆè‡ªç„¶èªå¥ã€‚
  - ç¯„ä¾‹ï¼š
    - "è©²å…¬å¸æä¾›é›²ç«¯ ERP åŠå®¢è£½åŒ–ç³»çµ±æ•´åˆæœå‹™ï¼Œä¸»è¦å®¢æˆ¶ç‚ºä¸­å¤§å‹ä¼æ¥­ï¼Œå› æ­¤æ­¸é¡ç‚ºè³‡è¨Šç§‘æŠ€èˆ‡è»Ÿé«”é–‹ç™¼ç›¸é—œç”¢æ¥­ã€‚"

- confidenceï¼š
  - 0ï½1 ä¹‹é–“çš„å°æ•¸ï¼Œä»£è¡¨ä½ å°é€™å€‹ç”¢æ¥­åˆ†é¡åˆ¤æ–·çš„ä¿¡å¿ƒç¨‹åº¦ã€‚
  - å»ºè­°ï¼š
    - è³‡è¨Šå……è¶³ä¸”ä¾†æºæ¸…æ¥š â†’ 0.8ï½1.0
    - æœ‰éƒ¨åˆ†è³‡è¨Šï¼Œä½†ä»æœ‰æ¨¡ç³Šç©ºé–“ â†’ 0.5ï½0.79
    - å¹¾ä¹æŸ¥ä¸åˆ°è³‡æ–™ï¼Œåªèƒ½åšéå¸¸ç²—ç•¥æ¨æ¸¬ â†’ 0.0ï½0.49
  - è«‹è¼¸å‡ºæœ€å¤šå°æ•¸é»å…©ä½ï¼Œä¾‹å¦‚ 0.86, 0.4ã€‚

ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘
1. æœ€çµ‚åªå…è¨±è¼¸å‡ºä¸€å€‹ JSON ç‰©ä»¶ã€‚
2. ä¸è¦åœ¨ JSON ä¹‹å¤–åŠ å…¥ä»»ä½•è§£èªªæ–‡å­—æˆ–è¨»è§£ã€‚
3. JSON çš„ key å¿…é ˆå›ºå®šç‚ºï¼š
   - "major_category_12"
   - "primary_label"
   - "labels"
   - "description"
   - "confidence"

ã€è¼¸å‡ºç¯„ä¾‹ã€‘ï¼ˆæ³¨æ„ï¼šé€™åªæ˜¯ç¯„ä¾‹ï¼Œå¯¦éš›è«‹ä¾æŸ¥è©¢çµæœåˆ¤æ–·ï¼‰
{
  "major_category_12": "è³‡è¨Šç§‘æŠ€",
  "primary_label": "è³‡è¨Šç§‘æŠ€",
  "labels": ["è³‡è¨Šç§‘æŠ€", "è»Ÿé«”é–‹ç™¼", "SaaS"],
  "description": "æä¾›B2Bè»Ÿé«”æœå‹™ã€ç³»çµ±é–‹ç™¼æˆ–é›²ç«¯å¹³å°çš„ç§‘æŠ€å…¬å¸ã€‚",
  "confidence": 0.86
}

è«‹ä¾ç…§ä¸Šè¿°è¦å‰‡ï¼Œé‡å°ä»¥ä¸‹å…¬å¸ç”¢ç”Ÿåˆ†é¡çµæœï¼š
å…¬å¸ä¸­æ–‡åç¨±: {{company_name_zh}}
å…¬å¸è‹±æ–‡åç¨±: {{company_name_en}}

è«‹åªè¼¸å‡ºä¸€å€‹ JSON ç‰©ä»¶ï¼Œä¸èƒ½æœ‰å…¶ä»–è§£èªªæ–‡å­—ã€‚
"""

    def __init__(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ + mapping cache"""
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
        # å»ºè­°é è¨­æ”¹æˆ gpt-4o-miniï¼ˆå¯ä»¥å†ç”¨ç’°å¢ƒè®Šæ•¸è¦†è“‹ï¼‰
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.timeout = int(os.getenv("OPENAI_TIMEOUT", "60"))

        self._mapping_dict: Dict[str, Dict] = {}
        self._mapping_list: List[Dict] = []
        self._mapping_loaded = False

        logger.info(
            f"åˆå§‹åŒ– AI åˆ†ç±»æœåŠ¡: model={self.model}, base_url={os.getenv('OPENAI_BASE_URL')}, "
            f"mapping_path={self.MAPPING_PATH}"
        )

    # ===================== Normalization & mapping =====================

    @staticmethod
    def _normalize_width(text: str) -> str:
        return unicodedata.normalize("NFKC", text)

    @staticmethod
    def _remove_parentheses(text: str) -> str:
        return re.sub(r"[ï¼ˆ(].*?[ï¼‰)]", "", text).strip()

    def _clean_company_name_strong(self, name: Optional[str]) -> str:
        if not name:
            return ""
        name = self._normalize_width(name).strip()
        if not name:
            return ""

        name = self._remove_parentheses(name)

        zh_suffixes = [
            "è‚¡ä»½æœ‰é™å…¬å¸è‡ºç£åˆ†å…¬å¸",
            "è‚¡ä»½æœ‰é™å…¬å¸å°ç£åˆ†å…¬å¸",
            "è‚¡ä»½æœ‰é™å…¬å¸å°åŒ—åˆ†å…¬å¸",
            "è‚¡ä»½æœ‰é™å…¬å¸åˆ†å…¬å¸",
            "æœ‰é™å…¬å¸è‡ºç£åˆ†å…¬å¸",
            "æœ‰é™å…¬å¸å°ç£åˆ†å…¬å¸",
            "æœ‰é™å…¬å¸å°åŒ—åˆ†å…¬å¸",
            "æœ‰é™å…¬å¸åˆ†å…¬å¸",
            "ä¼æ¥­è‚¡ä»½æœ‰é™å…¬å¸",
            "ä¼æ¥­æœ‰é™å…¬å¸",
            "æœ‰é™è‚¡ä»½å…¬å¸",
            "è‚¡ä»½æœ‰é™å…¬å¸",
            "æœ‰é™å…¬å¸",
            "è‚¡ä»½å…¬å¸",
            "ä¼æ¥­",
            "æ§è‚¡å…¬å¸",
            "æ§è‚¡",
            "é›†åœ˜",
            "äº‹æ¥­éƒ¨",
            "äº‹æ¥­ç¾¤",
            "äº‹æ¥­è™•",
            "äº‹æ¥­å–®ä½",
            "åˆ†å…¬å¸",
            "ç¸½å…¬å¸",
            "åˆ†è¡Œ",
            "åˆ†éƒ¨",
            "éƒ¨é–€",
            "éƒ¨",
            "èª²",
            "çµ„",
            "è™•",
            "å…¬å¸",
        ]
        for suf in zh_suffixes:
            if name.endswith(suf):
                name = name[: -len(suf)].strip()
                break

        lowered = name.lower().rstrip(" .,")

        en_suffixes = [
            "co., ltd",
            "co, ltd",
            "co ltd",
            "co.,ltd",
            "company ltd",
            "company limited",
            "inc.",
            "inc",
            "corp.",
            "corp",
            "corporation",
            "limited",
            "ltd.",
            "ltd",
        ]
        for suf in en_suffixes:
            if lowered.endswith(suf):
                cut_len = len(suf)
                name = name[: -cut_len].rstrip(" .,")
                break

        name = re.sub(r"\s+", " ", name)
        return name.strip()

    def _make_company_key(self, company_name_zh: Optional[str], company_name_en: Optional[str]) -> Optional[str]:
        raw_zh = (company_name_zh or "").strip()
        raw_en = (company_name_en or "").strip()

        cleaned_zh = self._clean_company_name_strong(raw_zh) if raw_zh else ""
        cleaned_en = self._clean_company_name_strong(raw_en) if raw_en else ""

        if cleaned_zh:
            return cleaned_zh
        elif cleaned_en:
            return cleaned_en
        elif raw_zh:
            return raw_zh
        elif raw_en:
            return raw_en
        else:
            return None

    def _load_mapping(self) -> None:
        """è¼‰å…¥ mapping JSON åˆ°è¨˜æ†¶é«”ï¼ˆåªè¼‰å…¥ä¸€æ¬¡ï¼‰"""
        if self._mapping_loaded:
            return

        if not self.MAPPING_PATH.exists():
            logger.warning(f"æ‰¾ä¸åˆ° mapping æª”æ¡ˆï¼š{self.MAPPING_PATH}ï¼Œå°‡å¾ç©ºç™½é–‹å§‹")
            self._mapping_dict = {}
            self._mapping_list = []
            self._mapping_loaded = True
            return

        data = json.loads(self.MAPPING_PATH.read_text(encoding="utf-8"))
        if not isinstance(data, list):
            raise ValueError(f"mapping æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œé æœŸç‚º listï¼Œå¯¦éš›ç‚º {type(data)}")

        mapping_dict: Dict[str, Dict] = {}
        for entry in data:
            key = entry.get("company_key")
            if not key:
                continue
            mapping_dict[key] = entry

        self._mapping_dict = mapping_dict
        self._mapping_list = data
        self._mapping_loaded = True

        logger.info(f"è¼‰å…¥ mapping å®Œæˆï¼Œå…± {len(self._mapping_dict)} ç­†å…¬å¸ï¼ˆcompany_keyï¼‰")

    def _save_mapping(self) -> None:
        """æŠŠè¨˜æ†¶é«”ä¸­çš„ mapping_list å¯«å›æª”æ¡ˆ"""
        if not self._mapping_loaded:
            return
        self.MAPPING_PATH.parent.mkdir(parents=True, exist_ok=True)
        self.MAPPING_PATH.write_text(
            json.dumps(self._mapping_list, indent=2, ensure_ascii=False),
            encoding="utf-8",
        )

    # ===================== GPT å«ç”¨é‚è¼¯ =====================

    def _call_gpt_classification(self, company_name_zh: Optional[str], company_name_en: Optional[str]) -> Dict:
        """
        å‘¼å« GPTï¼ˆå« web_searchï¼‰åšä¸€æ¬¡å…¬å¸åˆ†é¡ã€‚
        å›å‚³ JSONï¼š
          {
            "major_category_12": "...",
            "primary_label": "...",
            "labels": [...],
            "description": "...",
            "confidence": 0.xx
          }
        """
        user_message = (
            f"å…¬å¸ä¸­æ–‡åç¨±: {company_name_zh or ''}\n"
            f"å…¬å¸è‹±æ–‡åç¨±: {company_name_en or ''}\n\n"
            "è«‹ä¾ç…§ system prompt çš„è¦å‰‡ï¼Œåªè¼¸å‡ºä¸€å€‹ JSON ç‰©ä»¶ã€‚"
        )

        logger.info(f"å‘¼å« GPT é€²è¡Œç”¢æ¥­åˆ†é¡ï¼šzh={company_name_zh}, en={company_name_en}")

        response = self.client.responses.create(
            model=self.model,
            input=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": user_message},
            ],
            tools=[{"type": "web_search"}],
            timeout=self.timeout,
        )

        result_text = response.output_text
        logger.debug(f"GPT åŸå§‹è¼¸å‡ºï¼š{result_text}")

        try:
            data = json.loads(result_text)
        except Exception as e:
            logger.error(f"è§£æ GPT JSON å¤±æ•—ï¼Œæ”¹ç”¨é è¨­ fallbackï¼š{e}")
            return {
                "major_category_12": "ä¸æ˜ï¼å…¶ä»–",
                "primary_label": "å…¶ä»–",
                "labels": ["å…¶ä»–"],
                "description": "è§£æ GPT å›æ‡‰å¤±æ•—ï¼Œä½¿ç”¨é è¨­åˆ†é¡ã€‚",
                "confidence": 0.0,
            }

        return data

    # ===================== mapping æŸ¥è©¢ & æ›´æ–° =====================

    def _lookup_from_mapping(self, company_name_zh: Optional[str], company_name_en: Optional[str]) -> Tuple[Optional[str], Optional[Dict]]:
        self._load_mapping()
        key = self._make_company_key(company_name_zh, company_name_en)
        if not key:
            return None, None

        entry = self._mapping_dict.get(key)
        if entry is None:
            return key, None
        return key, entry

    def _add_or_update_mapping_entry(
        self,
        company_name_zh: Optional[str],
        company_name_en: Optional[str],
        classification: Dict,
    ) -> Tuple[str, Dict]:
        """
        å°‡ GPT åˆ†é¡çµæœå¯«å› mappingï¼š
          - è‹¥ mapping æ²’æœ‰æ­¤ key â†’ æ–°å¢
          - è‹¥å·²æœ‰ â†’ æ¯”è¼ƒ confidenceï¼Œæ–°çš„è¼ƒé«˜æ‰è¦†å¯«
        """
        self._load_mapping()
        key = self._make_company_key(company_name_zh, company_name_en)
        if not key:
            raise ValueError("ç„¡æ³•ç‚ºå…¬å¸åç¨±ç”¢ç”Ÿ company_key")

        major_category_12 = classification.get("major_category_12")
        primary_label = classification.get("primary_label")
        labels = classification.get("labels") or []
        description = classification.get("description")
        confidence = classification.get("confidence")

        # âœ… å¼·åˆ¶æŠŠ major_category_12 ä¿®æ­£æˆ 12 å¤§é¡ä¹‹ä¸€ï¼ˆåªæ ¹æ“š major + primaryï¼‰
        major_category_12 = self._normalize_major_category_12(
            major=major_category_12,
            primary_label=primary_label,
        )

        ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        old_entry = self._mapping_dict.get(key)

        if old_entry is None:
            entry = {
                "company_key": key,
                "company_name_zh": self._clean_company_name_strong(company_name_zh) if company_name_zh else None,
                "company_name_en": self._clean_company_name_strong(company_name_en) if company_name_en else None,
                "aliases": sorted({n for n in [company_name_zh, company_name_en] if n}),
                "classification_timestamp": ts,
                "major_category_12": major_category_12,
                "primary_label": primary_label,
                "labels": labels,
                "description": description,
                "confidence": confidence,
            }
            self._mapping_dict[key] = entry
            self._mapping_list.append(entry)
            self._save_mapping()
            return key, entry

        # å·²å­˜åœ¨ â†’ æ¯”è¼ƒä¿¡å¿ƒåˆ†æ•¸
        def _to_float(val):
            try:
                return float(val)
            except Exception:
                return -1.0

        old_c = _to_float(old_entry.get("confidence"))
        new_c = _to_float(confidence)

        alias_set = set(old_entry.get("aliases") or [])
        for n in [company_name_zh, company_name_en]:
            if n:
                alias_set.add(n)
        old_entry["aliases"] = sorted(alias_set)

        if new_c > old_c:
            old_entry["classification_timestamp"] = ts
            old_entry["major_category_12"] = major_category_12
            old_entry["primary_label"] = primary_label
            old_entry["labels"] = labels
            old_entry["description"] = description
            old_entry["confidence"] = confidence
            self._save_mapping()
            return key, old_entry

        # æ–°çš„ä¿¡å¿ƒä¸æ¯”è¼ƒé«˜ï¼Œåªæ›´æ–° aliases
        self._save_mapping()
        return key, old_entry
    

    def _build_structured_reason(
        self,
        primary_label: Optional[str],
        labels: list,
    ) -> str:
        """
        ç”¢ç”Ÿä¹¾æ·¨ç‰ˆçš„çµæ§‹åŒ– classification_reasonï¼Œ
        æ ¼å¼ç¯„ä¾‹ï¼š
            primary=é‡‘èç§‘æŠ€, labels=é‡‘èä¿éšª,é‡‘èç§‘æŠ€,æ•¸ä½æ”¯ä»˜,å€å¡Šéˆ,åŠ å¯†è²¨å¹£
        """
        parts = []
        if primary_label:
            parts.append(f"primary={primary_label}")
        if labels:
            labels_str = ",".join(labels)
            parts.append(f"labels={labels_str}")

        return ", ".join(parts)
    

    def _normalize_major_category_12(
        self,
        major: Optional[str],
        primary_label: Optional[str],
    ) -> str:
        """
        å¼·åˆ¶æŠŠ major_category_12 ä¿®æ­£æˆ 12 å¤§é¡ä¹‹ä¸€ï¼ˆåªçœ‹ major+primaryï¼Œä¸çœ‹ labelsï¼‰ï¼š
        1. è‹¥ major æœ¬èº«å°±åœ¨ 12 é¡è£¡ â†’ ç›´æ¥ç”¨
        2. è‹¥ä¸åœ¨ â†’ ç”¨ (major + primary_label) çš„é—œéµå­—åšç²—åˆ†é¡
        3. é‚„æ˜¯çŒœä¸åˆ° â†’ çµ±ä¸€ä¸Ÿã€Œå…¶ä»–ï¼ˆç„¡æ³•æ­¸é¡æ‰ä½¿ç”¨ï¼‰ã€
        """
        # è‹¥åŸæœ¬å°±å·²åˆæ³•ï¼Œç›´æ¥å›å‚³
        if major in self.MAJOR_12:
            return major

        text = f"{major or ''} {primary_label or ''}"

        # é‡‘èä¿éšª
        if any(k in text for k in ["é‡‘æ§", "éŠ€è¡Œ", "ä¿éšª", "è­‰åˆ¸", "æŠ•ä¿¡", "ç†è²¡", "é‡‘è"]):
            return "é‡‘èä¿éšª"

        # è£½é€ æ¥­ï¼å·¥æ¥­æ‡‰ç”¨
        if any(k in text for k in ["è£½é€ ", "å·¥æ¥­", "æ©Ÿæ¢°", "è¨­å‚™", "é›¶ä»¶", "åŠ å·¥", "ææ–™", "å·¥å» ", "åŠå°é«”", "é›»å­å…ƒä»¶", "OEM", "ODM"]):
            return "è£½é€ æ¥­ï¼å·¥æ¥­æ‡‰ç”¨"

        # å»ºç¯‰ä¸å‹•ç”¢
        if any(k in text for k in ["å»ºè¨­", "ç‡Ÿé€ ", "ä¸å‹•ç”¢", "åœ°ç”¢", "æˆ¿å±‹", "ä½å®…", "å•†è¾¦", "ç§Ÿè³ƒ", "ä»²ä»‹"]):
            return "å»ºç¯‰ä¸å‹•ç”¢"

        # äº¤é€šé‹è¼¸ï¼ç‰©æµ
        if any(k in text for k in ["ç‰©æµ", "é‹è¼¸", "å¿«é", "è²¨é‹", "èˆªé‹", "èˆªç©º", "é…é€", "å€‰å„²", "è»ŠéšŠ"]):
            return "äº¤é€šé‹è¼¸ï¼ç‰©æµ"

        # é†«ç™‚å¥åº·ï¼ç”ŸæŠ€
        if any(k in text for k in ["é†«ç™‚", "è¨ºæ‰€", "é†«é™¢", "è—¥å±€", "è—¥å“", "ç”ŸæŠ€", "é†«æ", "ä¿å¥", "å¥åº·", "è£½è—¥"]):
            return "é†«ç™‚å¥åº·ï¼ç”ŸæŠ€"

        # é¤é£²ï¼é›¶å”®ï¼é€šè·¯
        if any(k in text for k in ["é¤é£²", "é¤å»³", "å’–å•¡", "é£²æ–™", "è¶…å•†", "è¶…å¸‚", "é‡è²©", "ç™¾è²¨", "é›¶å”®", "è³£å ´", "é€šè·¯"]):
            return "é¤é£²ï¼é›¶å”®ï¼é€šè·¯"

        # å»£å‘Šï¼åª’é«”ï¼è¡ŒéŠ·
        if any(k in text for k in ["å»£å‘Š", "è¡ŒéŠ·", "åª’é«”", "å…¬é—œ", "branding", "å“ç‰Œ", "æ•¸ä½è¡ŒéŠ·", "æ•´åˆè¡ŒéŠ·", "martech"]):
            return "å»£å‘Šï¼åª’é«”ï¼è¡ŒéŠ·"

        # æ•™è‚²ï¼å­¸ç ”
        if any(k in text for k in ["å­¸æ ¡", "å¤§å­¸", "å­¸é™¢", "è£œç¿’", "æ•™è‚²", "å­¸ç¿’", "ç ”ç™¼", "ç ”ç©¶ä¸­å¿ƒ", "ç ”ç©¶æ‰€", "åŸ¹è¨“"]):
            return "æ•™è‚²ï¼å­¸ç ”"

        # æ”¿åºœï¼å…¬éƒ¨é–€ï¼éç‡Ÿåˆ©
        if any(k in text for k in ["å¸‚æ”¿åºœ", "ç¸£æ”¿åºœ", "å…¬æ‰€", "éƒ¨æœƒ", "ç½²", "å±€", "æ”¿åºœ", "å”æœƒ", "åŸºé‡‘æœƒ", "å…¬æœƒ", "éç‡Ÿåˆ©", "NPO", "NGO"]):
            return "æ”¿åºœï¼å…¬éƒ¨é–€ï¼éç‡Ÿåˆ©"

        # å°ˆæ¥­æœå‹™ï¼ˆé¡§å•ï¼æ³•å‹™ï¼æœƒè¨ˆç­‰ï¼‰
        if any(k in text for k in ["é¡§å•", "consulting", "æœƒè¨ˆ", "è¨˜å¸³", "å¯©è¨ˆ", "å¾‹å¸«", "æ³•å¾‹", "è¨­è¨ˆäº‹å‹™æ‰€", "åœ°æ”¿å£«", "ä»£æ›¸", "äººåŠ›è³‡æº", "çµé ­"]):
            return "å°ˆæ¥­æœå‹™ï¼ˆé¡§å•ï¼æ³•å‹™ï¼æœƒè¨ˆç­‰ï¼‰"

        # è³‡è¨Šç§‘æŠ€ï¼ˆå¾ˆå¸¸è¦‹ï¼Œæ”¾æœ€å¾Œï¼‰
        if any(k in text for k in ["è³‡è¨Š", "è»Ÿé«”", "SaaS", "é›²ç«¯", "ç³»çµ±", "å¹³å°", "app", "AI", "äººå·¥æ™ºæ…§", "IT", "ç¶²è·¯", "ç§‘æŠ€", "æ•¸ä½è½‰å‹"]):
            return "è³‡è¨Šç§‘æŠ€"

        # çœŸçš„å®Œå…¨çœ‹ä¸å‡ºä¾†å°±ä¸Ÿå…¶ä»–
        return "ä¸æ˜ï¼å…¶ä»–"




    # ===================== å°å¤–ï¼šå–®ç­† classification pipeline =====================

    def _classify_runtime(self, company_name_zh: Optional[str], company_name_en: Optional[str]) -> Dict[str, any]:
        """
        æ–°ç‰ˆå–®ç­†åˆ†é¡æµç¨‹ï¼ˆä¸å« retryï¼‰ï¼š
        1. å…ˆæŸ¥ mapping
        2. æ‰¾ä¸åˆ°æ™‚ call GPT + web_searchï¼Œä¸¦æ›´æ–° mapping
        3. å›å‚³æ ¼å¼ï¼š
            {
                "industry_category": <12å¤§é¡>,
                "confidence": <0~1 å°æ•¸>,
                "reason": çµæ§‹åŒ–å­—ä¸² (primary + labels + key),
                "source": "mapping" / "gpt_new",
                "classified_at": <æ™‚é–“å­—ä¸²>,
                "success": True/False,
            }
        """
        self._load_mapping()
        key, entry = self._lookup_from_mapping(company_name_zh, company_name_en)

        # ---- 1. å…ˆç”¨ mapping ----
        if key and entry:
            source = "mapping"
            major = entry.get("major_category_12") or "ä¸æ˜ï¼å…¶ä»–"
            primary = entry.get("primary_label")
            labels = entry.get("labels") or []
            raw_conf = entry.get("confidence")

            # çµ±ä¸€ç”¨ 0~1 å°æ•¸
            try:
                conf_float = float(raw_conf) if raw_conf is not None else 0.0
            except Exception:
                conf_float = 0.0
            conf_float = max(0.0, min(1.0, conf_float))

            # çµæ§‹åŒ– reason
            reason = self._build_structured_reason(
                primary_label=primary,
                labels=labels,
            )

            classified_at = entry.get("classification_timestamp") or datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            return {
                "industry_category": major,
                "confidence": conf_float,
                "reason": reason,
                "source": source,
                "classified_at": classified_at,
                "success": True,
            }

        # ---- 2. mapping æ²’æœ‰ â†’ call GPT + æ›´æ–° mapping ----
        cls = self._call_gpt_classification(company_name_zh, company_name_en)
        source = "gpt_new"
        key, final_entry = self._add_or_update_mapping_entry(company_name_zh, company_name_en, cls)

        major = final_entry.get("major_category_12") or "ä¸æ˜ï¼å…¶ä»–"
        primary = final_entry.get("primary_label")
        labels = final_entry.get("labels") or []
        raw_conf = final_entry.get("confidence")

        try:
            conf_float = float(raw_conf) if raw_conf is not None else 0.0
        except Exception:
            conf_float = 0.0
        conf_float = max(0.0, min(1.0, conf_float))

        reason = self._build_structured_reason(
            primary_label=primary,
            labels=labels,
        )

        classified_at = final_entry.get("classification_timestamp") or datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        return {
            "industry_category": major,
            "confidence": conf_float,
            "reason": reason,
            "source": source,
            "classified_at": classified_at,
            "success": True,
        }

    # ===================== å°å¤–æ¥å£ï¼šç¶­æŒåŸæœ¬ method ä»‹é¢ =====================

    def classify_single(self, company_name: str, position: str) -> Dict[str, any]:
        """
        å–®ç­†åˆ†é¡ï¼ˆç›¸å®¹èˆŠä»‹é¢ï¼‰
        æ–°å¢åŠŸèƒ½ï¼šè‡ªå‹•åˆ¤æ–· company_name æ˜¯ä¸­æ–‡é‚„æ˜¯è‹±æ–‡
        ç„¶å¾Œå°‡ zh + en åˆ†é–‹æ¬„ä½ï¼Œèˆ‡æ‰¹æ¬¡é‚è¼¯å®Œå…¨ä¸€è‡´
        """

        def detect_lang(name: str):
            # æœ‰ä¸­æ–‡å­— â†’ ä¸­æ–‡å
            if re.search(r"[\u4e00-\u9fff]", name):
                return "zh"
            # æ²’ä¸­æ–‡ â†’ ç•¶ä½œè‹±æ–‡
            return "en"

        lang = detect_lang(company_name)

        if lang == "zh":
            company_name_zh = company_name
            company_name_en = None
        else:
            company_name_zh = None
            company_name_en = company_name
        try:
            logger.info(f"[å–®ç­†åˆ†é¡] zh={company_name_zh}, en={company_name_en}")

            # ğŸ”¥ é€™è£¡é–‹å§‹èˆ‡æ‰¹æ¬¡å®Œå…¨ä¸€è‡´ï¼
            result = self._classify_runtime(
                company_name_zh=company_name_zh,
                company_name_en=company_name_en
            )

            logger.info(f"[å–®ç­†åˆ†é¡å®Œæˆ] result={result}")

            return {
                "category": result["industry_category"],
                "confidence": result["confidence"],
                "reason": result["reason"],
            }

        except Exception as e:
            logger.error(f"AI åˆ†é¡å¤±æ•—: {str(e)}")
            return {
                "category": "ä¸æ˜ï¼å…¶ä»–",
                "confidence": 0,
                "reason": "",
            }

    def classify_batch(self, cards: List[Dict]) -> List[Dict]:
        """
        æ‰¹é‡åˆ†é¡åç‰‡ï¼ˆåŒæ­¥ï¼‰
        Args:
            cards: æ¯å€‹åç‰‡åŒ…å« id, company_name_zh/en, position_zh/en
        Returns:
            [
              {
                "card_id": ...,
                "industry_category": ...,
                "confidence": ...,
                "reason": ...,
                "success": True/False
              },
              ...
            ]
        """
        results = []
        total = len(cards)

        logger.info(f"é–‹å§‹æ‰¹é‡åˆ†é¡ {total} å¼µåç‰‡ï¼ˆåŒæ­¥ï¼‰")

        for index, card in enumerate(cards, 1):
            company_zh = card.get("company_name_zh")
            company_en = card.get("company_name_en")
            logger.info(f"[{index}/{total}] åˆ†ç±»åç‰‡ ID={card['id']} å…¬å¸={company_zh}/{company_en}")

            try:
                r = self._classify_runtime(company_zh, company_en)
                results.append({
                    "card_id": card["id"],
                    "industry_category": r["industry_category"],
                    "confidence": r["confidence"],
                    "reason": r["reason"],
                    "success": r["success"],
                })
            except Exception as e:
                logger.error(f"åç‰‡ {card['id']} æ‰¹é‡åˆ†é¡å¤±æ•—: {e}")
                results.append({
                    "card_id": card["id"],
                    "industry_category": "ä¸æ˜ï¼å…¶ä»–",
                    "confidence": 0,
                    "reason": "",
                    "success": False,
                })

        logger.info(
            f"æ‰¹é‡åˆ†é¡å®Œæˆ: ç¸½æ•¸={total}, æˆåŠŸ={sum(1 for r in results if r['success'])}"
        )
        return results

    def classify_single_with_retry(self, card: Dict, max_retries: int = 3) -> Dict:
        """
        æ–°ç‰ˆå–®å¼µåç‰‡åˆ†é¡ï¼ˆå¸¶é‡è©¦ï¼‰ï¼Œæœƒä½¿ç”¨ company_name_zh/en

        Args:
            card: åç‰‡è³‡æ–™
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
        """
        company_zh = card.get("company_name_zh")
        company_en = card.get("company_name_en")

        for attempt in range(max_retries):
            try:
                r = self._classify_runtime(company_zh, company_en)
                if r["success"] and r["confidence"] > 0:
                    return {
                        "card_id": card["id"],
                        "industry_category": r["industry_category"],
                        "confidence": r["confidence"],
                        "reason": r["reason"],
                        "success": True,
                    }

                if attempt < max_retries - 1:
                    logger.warning(
                        f"åç‰‡ {card['id']} åˆ†é¡ç½®ä¿¡åº¦ç‚º0ï¼Œé‡è©¦ {attempt + 1}/{max_retries - 1}"
                    )
                    time.sleep(1)

            except Exception as e:
                logger.error(
                    f"åç‰‡ {card['id']} åˆ†é¡å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {str(e)}"
                )
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return {
                        "card_id": card["id"],
                        "industry_category": "ä¸æ˜ï¼å…¶ä»–",
                        "confidence": 0,
                        "reason": "",
                        "success": False,
                    }

        return {
            "card_id": card["id"],
            "industry_category": "ä¸æ˜ï¼å…¶ä»–",
            "confidence": 0,
            "reason": "",
            "success": False,
        }

    def classify_batch_async(self, cards: List[Dict], task_id: str) -> List[Dict]:
        """
        ç•°æ­¥æ‰¹é‡åˆ†é¡åç‰‡ï¼ˆå¤šåŸ·è¡Œç·’ä½µç™¼ï¼‰

        Args:
            cards: åç‰‡åˆ—è¡¨
            task_id: ä»»å‹™ ID

        Returns:
            åˆ†é¡çµæœåˆ—è¡¨
        """
        total = len(cards)
        logger.info(f"é–‹å§‹ç•°æ­¥æ‰¹é‡åˆ†é¡ {total} å¼µåç‰‡ï¼Œä»»å‹™ID: {task_id}")

        results: List[Dict] = []
        max_workers = 5

        def process_card(card):
            if task_manager.is_cancelled(task_id):
                logger.info(f"ä»»å‹™ {task_id} å·²å–æ¶ˆï¼Œåœæ­¢è™•ç†åç‰‡ {card['id']}")
                return None

            result = self.classify_single_with_retry(card, max_retries=3)
            task_manager.update_progress(task_id, success=result["success"])
            return result

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_card = {executor.submit(process_card, card): card for card in cards}

            for future in as_completed(future_to_card):
                try:
                    result = future.result()
                    if result is not None:
                        results.append(result)
                except Exception as e:
                    card = future_to_card[future]
                    logger.error(f"è™•ç†åç‰‡ {card['id']} æ™‚ç™¼ç”Ÿç•°å¸¸: {str(e)}")
                    results.append({
                        "card_id": card["id"],
                        "industry_category": "ä¸æ˜ï¼å…¶ä»–",
                        "confidence": 0,
                        "reason": "",
                        "success": False,
                    })
                    task_manager.update_progress(task_id, success=False)

        success_count = sum(1 for r in results if r["success"])
        logger.info(
            f"ç•°æ­¥æ‰¹é‡åˆ†é¡å®Œæˆ: ä»»å‹™ID={task_id}, ç¸½æ•¸={total}, æˆåŠŸ={success_count}, å¤±æ•—={total - success_count}"
        )
        return results
